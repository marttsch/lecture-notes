\documentclass[mfit.tex]{subfiles}
\begin{document}

\subsection{The ergodic theorem for finite Markov chains}

Let $(\mathcal{X},P)$ where $P = (p_{x,y})_{x,y\in \mathcal{X}} = (p(y|x))_{x,y\in \mathcal{X}}$ is the transition matrix, $\mathcal{X}$.
and $\mu = (\mu_x)_{x \in \mathcal{X}}$ start distribution. $\prob_\mu$
$(X_n)_{n \in \N_0}$ Markov chain

Where is a suitable probability space?
It is called trajectory space $\Omega = \mathcal{X}^{\N_0}$

$\mathcal{A}$ is generated by all \enquote{cylinder sets}.
$k \in \N_0$, $a_0,\dots,a_k \in \mathcal{X}$: $C(a_0,\dots,a_k) = \{ \omega = (x_n)_{n \in \N_0}: x_0 = a_0,\dots,x_k=a_k \}$
inclusive $\Omega$

$X_n = n$-th projection
\[ \prob_\mu(C(a_0,\dots,a_k)) = \mu_{a_0} p_{a_0,a_1} \cdots p_{a_{k-1},a_k} \]

unique continuation to ($\sigma$-algebra) probability measure on $(\Omega,\mathcal{A})$.
\todo{add pic}

\begin{defi*}
  \begin{align*}
    s^\times(\omega) &\coloneqq \inf \{n \geq 0: X_n(\omega) = x\} \\
    t^\times(\omega) &\coloneqq \inf \{n \geq 1: X_n(\omega) = x \}
  \end{align*}
  $s^\times,t^\times: (\Omega,\mathcal{A}) \to \N_0 \cup \{\infty\}$ are called stopping times.
  \begin{align*}
    f_{x,y}^{(n)} &= \prob_x[s^y = n] \\
    u_{x,y}^{(n)} &= \prob_x[t^y = n]
  \end{align*}
  \begin{align*}
    f_{x,y}^{(0)} = \begin{cases} 1, & y = x \\ 0, & x \neq y \end{cases}
  \end{align*}
  If $x \neq y$, then $u_{x,y}^{(n)} = f_{x,y}^{(n)}$ for all $n$.
  $u_{x,x}^{(n)}$ is called the \enquote{first return probability} for $n \geq 1$.
  $u^{(0)} \equiv 0$ (always)
  \begin{align*}
    V_n^y = \begin{cases} 1, & X_n = y \\ 0, & X_n \neq y \end{cases}
  \end{align*}
  \begin{align*}
    \expect_x(V_n^y) = \expect(\mathbb{1_{[X_n = y]}}) = p_{x,y}^{(n)}
  \end{align*}
  Consider the generating function
  \begin{align*}
    G(x,y|z) &= G_{x,y}(z) = \sum_{n=0}^\infty p_{x,y}^{(n)} z^n \\
    F_{x,y}(z) &= \sum_{n=0}^\infty f_{x,y}^{(n)}z^n \\
    U_{x,y}(z) = \sum_{n=0}^\infty u_{x,y}^{(n)} z^n
  \end{align*}
  for $0 \leq z < 1$.
  since $\underbrace{G_{x,y} = G_{x,y}(1)}_{\expect_x(\sum_{n=0}^\infty V_n^y) \leq \infty}$, $\underbrace{F_{x,y} = F_{x,y}(1)}_{\prob_x[\exists n \geq 0: X_n = y] = \prob_x[s^y < \infty]}$, $U_{x,y} = U_{x,y}(1)$
  and $U_{x,x} = \prob_x[t^x < \infty]$
  And remember that $F_{x,x}(z) \equiv 1$.
\end{defi*}

\begin{rem}
  We use $\inf$ and not $\min$ since the infimum of the empty set is $+\infty$.
\end{rem}

\begin{rem}
  Actually, its for $0 \leq z \leq 1$ since $G_{x,y}$ could be $\infty$. But we can neglect this.
\end{rem}

\begin{theorem}
  ($0 \leq z < 1$)
  \begin{enumerate}[label=(\alph*)]
    \item $G_{x,x}(z) = \frac{1}{1 - U_{x,x}(z)}$
    \item $G_{x,y}(z) = F_{x,y}(z) G_{y,y}(z)$
    \item $U_{x,x}(z) = \sum_{y} p_{x,y} z F_{y,x}(z)$
    \item $x \neq y$: $F_{x,y}(z) = \sum_{w \in \mathcal{X}} p_{x,w} z F_{w,y}(z)$
    \item $G_{x,y}(z) = \delta_y(x) +  \sum_w G_{x,w}(z) p_{w,y} z$; you can think like the following (commutative matrix)
    $G(z) = (G_{x,y}(z))_{x,y\in\mathcal{X}} = \sum_{n=0}^\infty P^n z^n = I + G(z) P z = I + Pz G(z)$
    If $\mathcal{X}$ is finite and $0 < z < 1$ or $\abs{z}<1$ for $z \in \C$: $G/z) = \inv{I - zP}$
  \end{enumerate}
\end{theorem}

\begin{proof}
  $n \geq 1$. 
  \begin{align*}
    p_{x,x}^{(n)} &= \prob_x[X_n = x] = \sum_{k=1}^n \prob_x[X_n = x, t^1 = k] \\
    &= \sum_{k=1}^n \underbrace{\prob_x[t^x = k]}_{u_{x,x}^{(k)}} \cdot \underbrace{\prob_x[X_n = x | X_k = x, X_j \neq k (j = 1,\dots,k-1)]}_{p_{x,x}^{(n-k)} \text{ by Markov property}}
  \end{align*}
  \begin{align*}
    n \geq 1:& p_{x,x}^{(n)} = \sum_{k=0}^n u_{x,x}^{(k)} p_{x,x}^{(n-k)} \\
    n=0:& p_{x,x}^{(0)} = 1 \text{ and } u_{x,x}^{(0)} = 0
  \end{align*}
  Thus,
  \begin{align*}
    G_{x,x}(z) &= 1 + \sum_{n=0}^\infty \sum_{k=0}^n u_{x,x}^{(k)} p_{x,x}^{(n-k)} z^n \\
    &= 1 + \sum 1 + U_{x,x}(z) G_{x,x}(z)
  \end{align*}
  for $z < 1$: this proves (a).
  
  Ad b: replace $p_{x,x}^{(n)}$ with $p_{x,y}^{(n)}$ and start sum at $0$. Replace $t^x$ by $s^y$. Do as an exercise. (Special case $0$ is already in $s$ included. Then
  \[ p_{x,y}^{(n)} = \sum_{k=0}^n f_{x,y}^{(k)} p_{y,y}^{(n-k)} \]
  for all $n \geq 0$.
\end{proof}

\begin{defi*}
  $x \in \mathcal{X}$ is called \emph{recurrent} if $U_{x,x} = 1$, $\prob_x[t^x < \infty] = 1$.
  Otherwise $x$ is called \emph{transient}.
\end{defi*}

\begin{lemma}\label{l_1}
  $x \in \mathcal{X}$ recurrent if and only if $U_{x,x} = 1$.
\end{lemma}

\begin{rem}
  \begin{enumerate}
    \item[$\Rightarrow$] $x$ is recurrent $\Rightarrow G_{x,x} = \infty \Rightarrow U_{x,x} = 1$
  \end{enumerate}
\end{rem}

\begin{proof}
  \begin{enumerate}[label=(\alph*)]
    \item $(0 < z < 1$) $z$ is monotone increasing. + blabla
  \end{enumerate}
\end{proof}

\begin{lemma}
  $(\mathcal{X},P)$ irreducible then we distinguish two cases:
  \begin{enumerate}
    \item[rec.] $G_{x,y} = \infty$ for all $x,y$
    \item[trans] $G_{x,y} < \infty$ for all $x,y$.
  \end{enumerate}
\end{lemma}

\begin{proof}
  $x,y,x^\prime,y^\prime \in \mathcal{X}$ irreducible $\exists k,l: p_{x,x^\prime}^{(k)} > 0, p_{y^\prime,y}^{(l)} >0$
  Now consider
  $p_{x,x^\prime}^{(k)} p_{x^\prime,y^\prime}^{(n)} p_{y^\prime,y}^{(l)} \leq p_{x,y}^{k+n+l}$
  Use $p^k p^n p^l = p^{k+n+l}$.
  \begin{align*}
    \sum_{n=0}^\infty p_{x,x^\prime}^{(k)} p_{x^\prime,y^\prime}^{(n)} p_{y^\prime,y}^{(l)} &\leq \sum_{n=0}^\infty p_{x,y}^{k+n+l} \\
    \underbrace{p_{x,x^\prime}^{(k)}}_{>0} G_{x^\prime,y^\prime} \underbrace{p_{y^\prime,y}}_{> 0} \leq G_{x,y}
  \end{align*}
\end{proof}

Thus we have the following theorem.

\begin{theorem}
  Let $(\mathcal{X},P)$ be irreducible. Then the following are equivalent
    \begin{enumerate}
      \item  There exist $x,y$ such that $G_{x,y} = \infty$
      \item For all $x,y$: $G_{x,y} = \infty$
      \item There exists an $x$ such that $U_{x,x} = 1$
      \item For all $x$: $U_{x,x} = 1$
      \item $F_{x,y} = 1$ for all $x,y$.
    \end{enumerate}
\end{theorem}

\begin{proof}
  No proof (yet).
\end{proof}

\begin{lemma}
  If $(\mathcal{X},P)$ is finite and irreducible, then it is recurrent.
\end{lemma}

\begin{proof}
  \begin{align*}
    \sum_y p_{x,y}^{(n)} = 1 \\
    \sum_{n=0}^\infty \sum_y p_{x,y}^{(n)} = \infty
  \end{align*}
  Since we can use Fubini and get
  \[ \sum_{n=0}^\infty \sum_y p_{x,y}^{(n)} = \sum_{y \in \mathcal{X}} G_{x,y} \implies \exists y: G_{x,y} = \infty \]
\end{proof}

$\expect_x(t^x) = \sum_{n=1}^\infty n \underbrace{\prob_x[t^x = n]}_{u_{x,x}^{(n)}} = U_{x,x}^\prime (1-)$
Think about $u_{x,x}^{(n)} z^{n-1}$ to get the derivate of $U_{x,x}$


Recall and add $z^n$ to the proof before:
\begin{align*}
  \sum_y p_{x,y}^{(n)} z^n &= 1 \cdot z^n \\
  \sum_{n=0}^\infty \sum_y p_{x,y}^{(n)} z^n &= \frac{1}{1-z}
\end{align*}
Then for $0 < z < 1$:
\begin{align*}
  \sum_{y \in \mathcal{X}} G_{x,y}(z) = \frac{1}{1-z}
\end{align*}
\begin{align*}
  G_{x,x}(z) = 1 + \sum_y G_{x,y}(z) p_{y,x} z
\end{align*}
\begin{align*}
  \sum_{y \in \mathcal{X}} F_{x,y}(z) \frac{1 - z}{1 - U_{y,y(z)}} = 1 \\
\end{align*}
Now let $z$ be monotone increasing towards $1$:
\begin{align*}
  \sum_{x \in \mathcal{X}} F_{x,y} \frac{1}{U_{y,y}^\prime(1-)} = 1
\end{align*}
Since $\mathcal{X}$ is finite.

Assume: $U_{y,y}^\prime(1-) = \infty$ for all $y$ $\lightning$.
Thus, there exists a $y$ such that $U_{y,y}^\prime(1-) < \infty$.

Variante 1: 
Like right before the theorem of $(\mathcal{X},P)$ is irreducble,..., you can find a $C_{x,y}$ such that
\begin{align*}
  C_{x,y} \geq \frac{G_{x,x}(z)}{G_{y,y}(z)} = \frac{1 - U_{y,y}(z)}{1 - U_{x,x}(z)}
\end{align*}

\begin{defi*}
  $(\mathcal{X},P)$ is called positive recurrent if $\expect_x(t^x) < \infty$ for an (all) $x$.
  It is called null-recurrent if $\expect_x(t^x) = \infty$ for an (all) $x$.
\end{defi*}

\begin{lemma}
  $(\mathcal{X},P)$ finite and irreducible. then it is positive recurrent.
\end{lemma}

Our goal: \[ \frac{1}{n} \sum_{k=0}^{n-1} f(X_k) \] where $f: \mathcal{X} \to \R$.

\end{document}
